<!doctype html>
<html class="no-js" lang="">

<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <title>Taichi Aritomo / Look.as</title>
<!--    <meta name="description" content="Taichi Aritomo, Portfolio">-->
<!--    <meta name="viewport" content="width=device-width, initial-scale=1">-->
<!--    <link rel="apple-touch-icon" href="apple-touch-icon.png">-->

    <!-- CSS -->
    <link rel="stylesheet" href="../css/normalize.min.css">
    <link rel="stylesheet" href="../css/helper.min.css">
    <link rel="stylesheet" href="../css/subpage.css">
    <link rel="stylesheet" href="../css/lookas.css">

</head>
  
  <body>
        
    <div id="main" class="disappear">
      <div class="wrapper">
          <div class="header">
            <div id="my-name" onclick="goTo('../index.html')">
              <span id="cross">&#x2715;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span id="name"><a href="../index.html">Taichi Aritomo /</a></span>
            </div>
            <br><br>
            Look.as
          </div>
      </div>
      
        <div class="wrapper feature">
          <div id="lookas-img-container">
            <img id="lookas-img" src="../img/lookas/overview/lookas_01.jpg"/>
            <a class="fill-div-link" href="http://taichi.pink/lookas" target="_blank"></a>
          </div>
        </div>
        <div class="row">
          <div class="col-3-single">
            <p>
              In a seminar at Rutgers University, I researched the potential of using computation to inform <em>design decisions based on visual perception instead of aesthetics</em>.
            </p>
          </div>
          <div class="col-3-single">
            <p>
              I created a simple tool that doesn't assume any value-systems about "good design". It just uses a computer-vision algorithm to highlight areas that are likely to attract visual attention.
              <br><br>
            </p>
          </div>
          <div class="col-3-single">
            <p>
              The tool was made with the goal of facilitating a process of testing unexpected arrangements and evaluating them on the basis of perception.
            </p>
            <br>
            <a href="http://taichi.pink/lookas" target="_blank"><span class="big-link special">Try it!</span></a>
          </div>

        </div>
        
        <div class="wrapper feature">
          <div id="distance-img-container">
              <div id="distance-img"></div>
          </div>
          
          <div class="row" id="distance-img-captions">
            <div class="caption">
              <em>Viewing Distance...</em>
            </div>
            <div class="caption distance">
              0.5m
            </div>
            <div class="caption distance">
              1.0m
            </div>
            <div class="caption distance">
              2.0m
            </div>
          </div>
        </div>
        
        <div class="row">
          <div class="col-3-single">
            <h5>Technical Information</h5>
            <p>
              The tool was built with HTML Canvas, Javascript, and Quill, a WYSIWYG text-editor API. It uses the Spectral Residual algorithm, a fast but accurate algorithm that uses spectral analysis to simulate human visual attention.
            </p>
            <p>
              To make calculations fast enough for real-time updates, I implemented a Fast-Fourier Transform algorithm that was optimized for calculations specific to spectral analysis. The adjustable <em>viewing distance</em> is simulated by controlling the sample size of the image.
            </p>
          </div>
          <div class="col-3-single">
            <h5>Testing & Early Conclusions</h5>
            <p>
              In a small experiment, ten users were asked to design a notice with perceptual feedback, and ten were asked to design the same notice without perceptual feedback. It was difficult to see if there were any obvious differences in their resulting designs, and only some users said it had changed how they approached design.
            </p>
            <p>
              The experiment prompt was probably too open-ended to draw any isolated differences. Other feedback from the experiments guided me to change how the perceptual feedback was represented.
            </p>
            
          </div>
          <div class="col-3-single">
            <h5>Future Work</h5>
            <p>
              My next step for this project is to create a very simple web application that accepts any image source and scans it to provide perceptual feedback. If it were to download an image from a URL at regular intervals, then it could fit into a design workflow that involves exporting to a cloud-based folder.
            </p>
            <p>
              I would then try this workflow in some graphic exercises, such as the Architectural Lobby's <em><a href="http://kerningforacause.us/" target="_blank">Kerning for a Cause</a></em> competition.
            </p>
          </div>
        </div>
      
<!--
      <section>
        <div class="row">
          <div class="col-3-single">
            <h5>Testing</h5>
            <p>
              T
            </p>
          </div>
          <div class="col-3-single">
            <h5>Future work</h5>
            <p>
              To make calculations fast enough for real-time updates, I implemented a Fast-Fourier Transform algorithm that was optimized for calculations specific to spectral analysis. The adjustable <em>viewing distance</em> is simulated by controlling the sample size of the image.
            </p>
          </div>
          <div class="col-3-single">
            <br>
            <p>
               Built with HTML Canvas, Javascript, and Quill, a WYSIWYG text-editor API.
            </p>
          </div>
        </div>
      </section>
-->
      

      
        <div class="wrapper">
          <div class="colophon">
            Instructor: Mubbasir Kapadia. Algorithm from <a href="http://bcmi.sjtu.edu.cn/~zhangliqing/Papers/2007CVPR_Houxiaodi_04270292.pdf" target="_blank">Saliency Detection: A Spectral Residual Approach" by Xiaodi Hou and Liqing Zhang.</a>
          </div>
        </div>
      
<!--      <div class="wrapper">-->
        <footer>
          <div class="row">
            <div class="col-3-single">
              <span class="big-link" onclick="goTo('../index.html')">
                <a href="../index.html">
                  All Work
                </a>
              </span>
            </div>
            <div class="col-3-single">
              <span onclick="scrollToTop()" class="big-link">Top</span>
            </div>
            <div class="col-3-single">
              <span class="big-link" onclick="goTo('sc.html')">
                <a href="sc.html">
                  Next
                </a>
              </span>
            </div>
          </div>
        </footer>
<!--      </div>-->
    </div>
    
    <!--  many of us saidJavascript -->
    <script src="../js/plugins.min.js"></script>
    <!-- Polyfill for object-fit CSS property for images and videos in IE/Edge -->
<!--    <script src="js/objectFitPolyfill.min.js"></script>-->
    <script src="../js/subpage.js"></script>
    <script src="../js/lookas.js"></script>
  </body>
  
</html>